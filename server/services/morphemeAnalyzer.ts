// Enhanced Korean morpheme extraction with Hangul library support
import Hangul from 'hangul-js';

// Define MorphemeAnalysis type inline to avoid import issues
interface MorphemeAnalysis {
  isOptimized: boolean;
  isKeywordOptimized: boolean;
  isLengthOptimized: boolean;
  keywordMorphemeCount: number;
  characterCount: number;
  targetCharacterRange: string;
  issues: string[];
  suggestions: string[];
  customMorphemes: { used: string[], missing: string[] };
  isCustomMorphemesOptimized: boolean;
}

export function extractKoreanMorphemes(text: string): string[] {
  const morphemes: string[] = [];
  
  // Split by various Korean delimiters and extract meaningful segments
  const segments = text
    .split(/[\s.,!?;:'"()[\]{}\-_=+|\\\/~`@#$%^&*<>]+/)
    .filter(segment => segment.length > 0);
  
  for (const segment of segments) {
    // Extract Korean + alphanumeric sequences
    const matches = segment.match(/[ê°€-í£a-zA-Z0-9]+/g);
    if (matches) {
      for (const match of matches) {
        if (match.length >= 1) {
          // ì¶”ê°€ ì²˜ë¦¬: í•œêµ­ì–´ ë‹¨ì–´ì¸ ê²½ìš° ì¡°ì‚¬ ë¶„ë¦¬
          const processed = processKoreanWord(match);
          morphemes.push(...processed);
        }
      }
    }
  }
  
  console.log(`Extracted morphemes:`, morphemes.slice(0, 20)); // First 20 for debugging
  return morphemes;
}

// í•œêµ­ì–´ ë‹¨ì–´ ì²˜ë¦¬ - ì¡°ì‚¬ ë¶„ë¦¬ ë° ë³µí•©ì–´ ì²˜ë¦¬ (Hangul.js í™œìš©)
function processKoreanWord(word: string): string[] {
  const result: string[] = [];
  
  // í•œêµ­ì–´ê°€ ì•„ë‹Œ ê²½ìš° ê·¸ëŒ€ë¡œ ë°˜í™˜
  if (!/[ê°€-í£]/.test(word)) {
    return [word];
  }
  
  // Hangul.jsë¥¼ ì‚¬ìš©í•˜ì—¬ ë°›ì¹¨ í™•ì¸ (ì¡°ì‚¬ ì„ íƒì— ë„ì›€)
  const lastChar = word[word.length - 1];
  const disassembled = Hangul.disassemble(lastChar);
  const hasFinalConsonant = disassembled.length === 3; // ë°›ì¹¨ ìˆìŒ
  
  // í•œêµ­ì–´ ì¡°ì‚¬/ì–´ë¯¸ íŒ¨í„´ (ë¹ˆë„ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬)
  const postpositions = [
    // ì„œìˆ ê²© ì¡°ì‚¬ ë° ì–´ë¯¸ (ìš°ì„  ì²˜ë¦¬)
    'ì…ë‹ˆë‹¤', 'ìŠµë‹ˆë‹¤', 'ì˜€ìŠµë‹ˆë‹¤', 'í–ˆìŠµë‹ˆë‹¤', 'ë©ë‹ˆë‹¤',
    // ë³µí•© ì¡°ì‚¬
    'ì—ì„œëŠ”', 'ì—ì„œë„', 'ìœ¼ë¡œëŠ”', 'ë¡œëŠ”', 'ì—ê²ŒëŠ”', 'ì—ì„œì˜',
    // ê¸°ë³¸ ì¡°ì‚¬
    'ì—ì„œ', 'ìœ¼ë¡œ', 'ë¡œë¶€í„°', 'ê¹Œì§€', 'ì—ê²Œ', 'í•œí…Œ',
    'ì„', 'ë¥¼', 'ì´', 'ê°€', 'ì€', 'ëŠ”', 'ì˜', 'ì—', 'ë¡œ',
    'ì™€', 'ê³¼', 'ë„', 'ë§Œ', 'ë¶€í„°', 'ê»˜', 'ë”ëŸ¬',
    // ìš©ì–¸ ì–´ë¯¸
    'ë‹ˆë‹¤', 'ì´ë‹¤', 'í•©ë‹ˆë‹¤', 'ì…ë‹ˆ', 'ìˆìŠµë‹ˆ', 'ë©ë‹ˆ'
  ];
  
  // ì¡°ì‚¬ ë¶„ë¦¬ ì‹œë„ (ê¸´ ê²ƒë¶€í„° ë§¤ì¹­)
  for (const postposition of postpositions) {
    if (word.endsWith(postposition) && word.length > postposition.length + 1) {
      const stem = word.slice(0, -postposition.length);
      // ì–´ê°„ì´ ì˜ë¯¸ìˆëŠ” ê¸¸ì´ì¸ ê²½ìš°ì—ë§Œ ë¶„ë¦¬ (í•œê¸€ 1ê¸€ì ì´ìƒ)
      if (stem.length >= 1 && /[ê°€-í£]/.test(stem)) {
        result.push(stem);
        // ì¡°ì‚¬ë„ í•„ìš”í•˜ë©´ ì¶”ê°€ ê°€ëŠ¥ (í˜„ì¬ëŠ” ì–´ê°„ë§Œ ë°˜í™˜)
        return result;
      }
    }
  }
  
  // ì¡°ì‚¬ ë¶„ë¦¬ê°€ ì•ˆ ëœ ê²½ìš° ì›ë³¸ ë°˜í™˜
  result.push(word);
  return result;
}

// ğŸ†• ë¶„í•´ ê²°ê³¼ ìºì‹œ (ë™ì¼ í‚¤ì›Œë“œ ë°˜ë³µ ë°©ì§€)
const decompositionCache = new Map<string, string[]>();

// ğŸ†• AI ê¸°ë°˜ í‚¤ì›Œë“œ ë¶„í•´ (hangul-js ë³´ì¡°, ìºì‹± ì ìš©)
async function aiBasedKeywordDecomposer(keyword: string): Promise<string[]> {
  // ìºì‹œ í™•ì¸
  if (decompositionCache.has(keyword)) {
    console.log(`Using cached decomposition for "${keyword}"`);
    return decompositionCache.get(keyword)!;
  }

  try {
    const { GoogleGenAI } = await import('@google/genai');
    const ai = new GoogleGenAI({ 
      apiKey: process.env.GEMINI_API_KEY || process.env.GEMINI_API_KEY_ENV_VAR || '' 
    });

    // Hangul.jsë¥¼ ì‚¬ìš©í•˜ì—¬ í•œê¸€ ë¶„ì„ ë³´ì¡°
    const hasKorean = /[ê°€-í£]/.test(keyword);
    const disassembled = hasKorean ? Hangul.disassemble(keyword) : null;
    const analysisPart = disassembled ? `\nì°¸ê³ : ìì†Œ ë¶„ì„ ê²°ê³¼ ${disassembled.length}ê°œ ìì†Œ` : '';

    const prompt = `ë‹¤ìŒ í‚¤ì›Œë“œë¥¼ ì˜ë¯¸ìˆëŠ” ë‹¨ì–´ ë‹¨ìœ„ë¡œ ë¶„í•´í•˜ì„¸ìš”.

í‚¤ì›Œë“œ: "${keyword}"${analysisPart}

ê·œì¹™:
1. ìµœì†Œ ì˜ë¯¸ ë‹¨ìœ„ë¡œ ë¶„í•´ (ê° ë‹¨ì–´ê°€ ë…ë¦½ì  ì˜ë¯¸ë¥¼ ê°€ì ¸ì•¼ í•¨)
2. ë„ˆë¬´ ì‘ê²Œ ìª¼ê°œì§€ ë§ ê²ƒ (2ê¸€ì ì´ìƒ ê¶Œì¥)
3. ì˜ì–´/ìˆ«ìëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€ (ì˜ˆ: "BMW" â†’ ["BMW"])

ì •í™•í•œ ë¶„í•´ ì˜ˆì‹œ:
âœ… "ë²¤ì¸ ì—”ì§„ê²½ê³ ë“±" â†’ ["ë²¤ì¸ ", "ì—”ì§„", "ê²½ê³ ë“±"]
âœ… "ë¯¸ì…˜ì˜¤ì¼êµì²´ì£¼ê¸°" â†’ ["ë¯¸ì…˜", "ì˜¤ì¼", "êµì²´", "ì£¼ê¸°"]
âœ… "ëƒ‰ê°ìˆ˜ë¶€ë™ì•¡" â†’ ["ëƒ‰ê°ìˆ˜", "ë¶€ë™ì•¡"]  ğŸ‘ˆ ì¤‘ìš”: ëƒ‰ê°ìˆ˜ì™€ ë¶€ë™ì•¡ì€ ë³„ê°œ ë‹¨ì–´
âœ… "íƒ€ì´ì–´êµì²´ë¹„ìš©" â†’ ["íƒ€ì´ì–´", "êµì²´", "ë¹„ìš©"]
âœ… "ì˜ì–´í•™ì›ì¶”ì²œ" â†’ ["ì˜ì–´", "í•™ì›", "ì¶”ì²œ"]

âŒ "ëƒ‰ê°ìˆ˜ë¶€ë™ì•¡" â†’ ["ëƒ‰ê°", "ìˆ˜", "ë¶€ë™", "ì•¡"]  (ë„ˆë¬´ ì‘ê²Œ ìª¼ê°¬)
âŒ "ëƒ‰ê°ìˆ˜ë¶€ë™ì•¡" â†’ ["ëƒ‰ê°ìˆ˜ë¶€ë™ì•¡"]  (ë¶„í•´ ì•ˆ ë¨)

JSON ë°°ì—´ë¡œë§Œ ì‘ë‹µ (ì˜ˆ: ["ë‹¨ì–´1", "ë‹¨ì–´2", "ë‹¨ì–´3"])`;

    const response = await ai.models.generateContent({
      model: 'gemini-2.0-flash-exp',
      config: {
        responseMimeType: "application/json"
      },
      contents: [{
        role: 'user',
        parts: [{ text: prompt }]
      }]
    });

    const result = JSON.parse(response.text || '[]').filter((word: string) => word.length >= 1);
    console.log(`âœ¨ AI decomposition (Hangul.js enhanced): "${keyword}" â†’ [${result.join(', ')}]`);
    
    // ìºì‹œ ì €ì¥
    decompositionCache.set(keyword, result);
    return result;
  } catch (error) {
    console.error('AI decomposition failed, using enhanced fallback:', error);
    const fallback = fallbackPatternDecomposer(keyword);
    decompositionCache.set(keyword, fallback);
    return fallback;
  }
}

// í´ë°±: ê°œì„ ëœ íŒ¨í„´ ê¸°ë°˜ ë¶„í•´ (AI ì‹¤íŒ¨ ì‹œ)
function fallbackPatternDecomposer(text: string): string[] {
  console.log(`Using enhanced fallback pattern decomposition for: "${text}"`);
  
  // ì¼ë°˜ì ì¸ í•œêµ­ì–´ ë³µí•©ì–´ íŒ¨í„´ ì‚¬ì „
  const commonPatterns = [
    // ìë™ì°¨ ê´€ë ¨ - ë³µí•©ì–´ ë¨¼ì € ë§¤ì¹­
    { pattern: /ëƒ‰ê°ìˆ˜ë¶€ë™ì•¡/, parts: ['ëƒ‰ê°ìˆ˜', 'ë¶€ë™ì•¡'] },
    { pattern: /ì—”ì§„ì˜¤ì¼êµì²´/, parts: ['ì—”ì§„', 'ì˜¤ì¼', 'êµì²´'] },
    { pattern: /ë¯¸ì…˜ì˜¤ì¼êµì²´/, parts: ['ë¯¸ì…˜', 'ì˜¤ì¼', 'êµì²´'] },
    { pattern: /íƒ€ì´ì–´êµì²´ë¹„ìš©/, parts: ['íƒ€ì´ì–´', 'êµì²´', 'ë¹„ìš©'] },
    { pattern: /ë²¤ì¸ ì—”ì§„ê²½ê³ ë“±/, parts: ['ë²¤ì¸ ', 'ì—”ì§„', 'ê²½ê³ ë“±'] },
    { pattern: /ì—”ì§„ê²½ê³ ë“±/, parts: ['ì—”ì§„', 'ê²½ê³ ë“±'] },
    { pattern: /ë²¤ì¸ ì—”ì§„/, parts: ['ë²¤ì¸ ', 'ì—”ì§„'] },
    { pattern: /ì˜¤ì¼êµì²´/, parts: ['ì˜¤ì¼', 'êµì²´'] },
    { pattern: /íƒ€ì´ì–´êµì²´/, parts: ['íƒ€ì´ì–´', 'êµì²´'] },
    { pattern: /ë¸Œë ˆì´í¬íŒ¨ë“œ/, parts: ['ë¸Œë ˆì´í¬', 'íŒ¨ë“œ'] },
    { pattern: /ì—ì–´ì»¨í•„í„°/, parts: ['ì—ì–´ì»¨', 'í•„í„°'] },
    { pattern: /ëƒ‰ê°ìˆ˜/, parts: ['ëƒ‰ê°ìˆ˜'] },
    { pattern: /ë¶€ë™ì•¡/, parts: ['ë¶€ë™ì•¡'] },
    { pattern: /ì²¨ê°€ì œ/, parts: ['ì²¨ê°€ì œ'] },
    
    // êµìœ¡ ê´€ë ¨
    { pattern: /ì˜ì–´í•™ì›/, parts: ['ì˜ì–´', 'í•™ì›'] },
    { pattern: /ìˆ˜í•™í•™ì›/, parts: ['ìˆ˜í•™', 'í•™ì›'] },
    { pattern: /ì½”ë”©êµìœ¡/, parts: ['ì½”ë”©', 'êµìœ¡'] },
    { pattern: /ì˜¨ë¼ì¸ê°•ì˜/, parts: ['ì˜¨ë¼ì¸', 'ê°•ì˜'] },
    
    // ê¸°ìˆ  ê´€ë ¨
    { pattern: /ì¸ê³µì§€ëŠ¥/, parts: ['ì¸ê³µì§€ëŠ¥'] },
    { pattern: /ë¨¸ì‹ ëŸ¬ë‹/, parts: ['ë¨¸ì‹ ', 'ëŸ¬ë‹'] },
    { pattern: /ë”¥ëŸ¬ë‹/, parts: ['ë”¥', 'ëŸ¬ë‹'] },
    { pattern: /ë¹…ë°ì´í„°/, parts: ['ë¹…', 'ë°ì´í„°'] },
  ];
  
  const result: string[] = [];
  let pos = 0;
  
  while (pos < text.length) {
    const remaining = text.substring(pos);
    let matched = false;
    
    // 1. íŒ¨í„´ ë§¤ì¹­ ì‹œë„
    for (const { pattern, parts } of commonPatterns) {
      const match = remaining.match(pattern);
      if (match && match.index === 0) {
        result.push(...parts);
        pos += match[0].length;
        matched = true;
        break;
      }
    }
    
    if (matched) continue;
    
    // 2. ì˜ì–´+ìˆ«ì ì¶”ì¶œ
    const engMatch = remaining.match(/^[a-zA-Z0-9]+/);
    if (engMatch) {
      result.push(engMatch[0]);
      pos += engMatch[0].length;
      continue;
    }
    
    // 3. í•œê¸€ 2-3ê¸€ì ë‹¨ìœ„ ë¶„í•  (ê°œì„ )
    const korMatch = remaining.match(/^[ê°€-í£]+/);
    if (korMatch) {
      const korText = korMatch[0];
      
      // 3-1. ê¸¸ì´ì— ë”°ë¥¸ ìŠ¤ë§ˆíŠ¸ ë¶„í• 
      if (korText.length <= 2) {
        result.push(korText);
        pos += korText.length;
      } else if (korText.length === 3) {
        // 3ê¸€ì: ê·¸ëŒ€ë¡œ ë˜ëŠ” 2+1 ë¶„í• 
        result.push(korText.substring(0, 2));
        pos += 2;
      } else if (korText.length === 4) {
        // 4ê¸€ì: 2+2 ë¶„í• 
        result.push(korText.substring(0, 2));
        pos += 2;
      } else {
        // 5ê¸€ì ì´ìƒ: 2-3ê¸€ìì”©
        const segmentLength = Math.min(3, korText.length);
        result.push(korText.substring(0, segmentLength));
        pos += segmentLength;
      }
      continue;
    }
    
    pos++;
  }
  
  return result.filter(word => word.length >= 1);
}

// ì§€ëŠ¥ì  ë³µí•©ì–´ ë¶„í•´ í•¨ìˆ˜ (í•œêµ­ì–´ + ì˜ì–´ + ìˆ«ì í˜¼í•© ì§€ì›) - ì‚¬ì „ ê¸°ë°˜ (íê¸° ì˜ˆì •)
function intelligentKoreanDecomposer(text: string): string[] {
  console.log(`=== Intelligent decomposing: "${text}" ===`);
  
  // 1ë‹¨ê³„: í•µì‹¬ ë‹¨ì–´ ì‚¬ì „
  const coreWords = [
    // í•œêµ­ì–´ 2ê¸€ì í•µì‹¬ ëª…ì‚¬
    'ìë™', 'ì „ê¸°', 'ìˆ˜í•™', 'ì˜ì–´', 'êµ­ì–´', 'ê³¼í•™', 'ë¬¼ë¦¬', 'í™”í•™', 'ìƒë¬¼', 'ì—­ì‚¬', 'ì‚¬íšŒ',
    'í•™ì›', 'ê³¼ì™¸', 'êµìœ¡', 'í•™ìŠµ', 'ê³µë¶€', 'ì‹œí—˜', 'ì„±ì ', 'ì…ì‹œ', 'ìˆ˜ëŠ¥', 
    'ì—”ì§„', 'íƒ€ì´ì–´', 'ë¸Œë ˆì´í¬', 'ë°°í„°ë¦¬', 'ì—ì–´ì»¨', 'í•„í„°', 'ì„¼ì„œ', 'ë¶€í’ˆ', 'ë¯¸ì…˜',
    'ëƒ‰ê°', 'ì˜¤ì¼', 'êµì²´', 'ì ê²€', 'ìˆ˜ë¦¬', 'ì •ë¹„', 'ì‹œê¸°', 'ì£¼ê¸°', 'ë°©ë²•', 'ê°€ê²©',
    'ë¹„ìš©', 'ì¶”ì²œ', 'í›„ê¸°', 'ë¦¬ë·°', 'ì •ë³´', 'ì†Œì‹', 'ë‰´ìŠ¤', 'ì„œë¹„ìŠ¤', 'ì—…ì²´',
    'íšŒì‚¬', 'ì „ë¬¸', 'ë§ì¶¤', 'ê°œì¸', 'ì˜¨ë¼ì¸', 'í™”ìƒ', 'ëŒ€ë©´', 'ì½”ë”©', 'ê°œë°œ',
    'ì‹œìŠ¤í…œ', 'ë°ì´í„°', 'ë¨¸ì‹ ', 'ë”¥ëŸ¬ë‹', 'ë¹…ë°ì´í„°', 'ì–¸ì–´', 'ì¹˜ë£Œ', 'ì‹¬ë¦¬',
    'ë°œë‹¬', 'ì¬í™œ', 'ìƒë‹´', 'ì§€ì›', 'ì•„ì´', 'ì–´ë¦°ì´', 'ìœ ì•„', 'ì²­ì†Œë…„',
    'ë²¤ì¸ ', 'ê²½ê³ ', 'ê³ ë“±', 'ë²¤ì¸ ì—”',
    
    // í•œêµ­ì–´ 3ê¸€ì í•µì‹¬ ëª…ì‚¬  
    'ì˜¤í† ë°”ì´', 'í•˜ì´ë¸Œë¦¬ë“œ', 'ì¹œí™˜ê²½', 'ê²½ê³ ë“±', 'ì—”ì§„ê²½ê³ ', 'ì›¹ì‚¬ì´íŠ¸', 'í™ˆí˜ì´ì§€', 'ì»¤ë®¤ë‹ˆí‹°',
    'í”„ë¡œê·¸ë˜ë°', 'ì†Œí”„íŠ¸ì›¨ì–´', 'ë°ì´í„°ë² ì´ìŠ¤', 'ì¸ê³µì§€ëŠ¥', 'ì–¸ì–´ì¹˜ë£Œ', 'ì‹¬ë¦¬ì¹˜ë£Œ',
    'ë°œë‹¬ì¬í™œ', 'ì–¸ì–´ë°œë‹¬', 'ì‹¬ë¦¬ìƒë‹´',
    
    // í•œêµ­ì–´ 4ê¸€ì ì´ìƒ í•µì‹¬ ëª…ì‚¬ ë° ë³µí•©ì–´
    'ì§€êµ¬ê³¼í•™', 'ìš°ë¦¬ì•„ì´', 'ì•„ì´ì‹¬ë¦¬', 'ì‹¬ë¦¬ì§€ì›', 'ì§€ì›ì„œë¹„ìŠ¤', 'ìš°ë¦¬ì•„ì´ì‹¬ë¦¬',
    'ì‹¬ë¦¬ì§€ì›ì„œë¹„ìŠ¤', 'ìš°ë¦¬ì•„ì´ì‹¬ë¦¬ì§€ì›ì„œë¹„ìŠ¤',
    'ì—”ì§„ê²½ê³ ë“±', 'ë²¤ì¸ ì—”ì§„',
    
    // ì˜ì–´ ë‹¨ì–´ë“¤ (ì†Œë¬¸ìë¡œ ì €ì¥)
    'bmw', 'audi', 'benz', 'mercedes', 'hyundai', 'kia', 'lg', 'samsung',
    'coding', 'tuning', 'programming', 'filter', 'engine', 'tire', 'brake',
    'battery', 'sensor', 'system', 'data', 'machine', 'deep', 'learning',
    'big', 'software', 'database', 'ai', 'web', 'app', 'blog', 'site',
    
    // ì˜ì–´+ìˆ«ì ì¡°í•©ë“¤
    'a1', 'a3', 'a4', 'a6', 'a8', 'q3', 'q5', 'q7', 'q8',
    'x1', 'x3', 'x5', 'x7', 'i3', 'i8', 'm3', 'm5',
    'c200', 'c300', 'e200', 'e300', 's300', 's500',
    '520d', '530i', '540i', '10w30', '10w40', '5w30', '5w40'
  ];
  
  // 2ë‹¨ê³„: í•œêµ­ì–´ ì–´ë¯¸/ì ‘ë¯¸ì‚¬ íŒ¨í„´
  const suffixPatterns = ['ìˆ˜', 'ì œ', 'ê¸°', 'ë“±', 'ì°¨', 'í’ˆ', 'ë“œ', 'ê°’', 'ë¥ ', 'ëŸ‰', 'ë„'];
  
  // 3ë‹¨ê³„: ì§€ëŠ¥ì  ë¶„í•´ ì•Œê³ ë¦¬ì¦˜ (í•œì˜ í˜¼í•© ì§€ì›)
  function smartDecompose(text: string): string[] {
    const result: string[] = [];
    let pos = 0;
    
    while (pos < text.length) {
      let bestMatch = '';
      let bestLength = 0;
      
      // í˜„ì¬ ìœ„ì¹˜ì—ì„œ ê°€ì¥ ê¸´ ì˜ë¯¸ìˆëŠ” ë‹¨ì–´ ì°¾ê¸°
      for (let len = Math.min(8, text.length - pos); len >= 1; len--) {
        const candidate = text.substring(pos, pos + len);
        const candidateLower = candidate.toLowerCase();
        
        // í•œêµ­ì–´ ë‹¨ì–´ ë˜ëŠ” ì˜ì–´ ë‹¨ì–´ ë§¤ì¹­
        if (coreWords.includes(candidate) || coreWords.includes(candidateLower)) {
          if (len > bestLength) {
            bestMatch = candidate;
            bestLength = len;
          }
        }
      }
      
      if (bestMatch) {
        result.push(bestMatch);
        pos += bestLength;
      } else {
        // ì‚¬ì „ì— ì—†ëŠ” ê²½ìš° íŒ¨í„´ ê¸°ë°˜ ë¶„í•´
        const remaining = text.substring(pos);
        const analyzed = analyzeUnknownSegment(remaining);
        
        if (analyzed.length > 0) {
          result.push(analyzed[0]);
          pos += analyzed[0].length;
        } else {
          // ìµœí›„ì˜ ìˆ˜ë‹¨: ë¬¸ì ìœ í˜•ë³„ ë¶„í• 
          const segmentInfo = getSegmentInfo(remaining);
          if (segmentInfo.length >= 1) {
            result.push(segmentInfo.segment);
            pos += segmentInfo.length;
          } else {
            pos++; // 1ê¸€ìëŠ” ê±´ë„ˆë›°ê¸°
          }
        }
      }
    }
    
    return result.filter(word => word.length >= 1); // ì˜ì–´ë‚˜ ìˆ«ìëŠ” 1ê¸€ìë„ í—ˆìš©
  }
  
  // ìƒˆë¡œìš´ í•¨ìˆ˜: ë¬¸ì ìœ í˜•ë³„ ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´ ë°˜í™˜
  function getSegmentInfo(text: string): { segment: string; length: number } {
    if (text.length === 0) return { segment: '', length: 0 };
    
    const firstChar = text[0];
    
    // ì˜ì–´ì¸ ê²½ìš°
    if (/[a-zA-Z]/.test(firstChar)) {
      const match = text.match(/^[a-zA-Z0-9]+/);
      return { segment: match ? match[0] : firstChar, length: match ? match[0].length : 1 };
    }
    
    // ìˆ«ìì¸ ê²½ìš°
    if (/[0-9]/.test(firstChar)) {
      const match = text.match(/^[0-9]+[a-zA-Z]*/);
      return { segment: match ? match[0] : firstChar, length: match ? match[0].length : 1 };
    }
    
    // í•œêµ­ì–´ì¸ ê²½ìš°
    if (/[ê°€-í£]/.test(firstChar)) {
      const koreanMatch = text.match(/^[ê°€-í£]+/);
      if (koreanMatch) {
        const segment = koreanMatch[0];
        // 2-3ê¸€ìì”© ë¶„í• 
        const segmentLength = Math.min(3, segment.length);
        return { segment: segment.substring(0, segmentLength), length: segmentLength };
      }
    }
    
    return { segment: firstChar, length: 1 };
  }
  
  // 4ë‹¨ê³„: ë¯¸ì§€ì˜ ì„¸ê·¸ë¨¼íŠ¸ ë¶„ì„ (í•œì˜ í˜¼í•© ì§€ì›)
  function analyzeUnknownSegment(segment: string): string[] {
    console.log(`Analyzing unknown segment: "${segment}"`);
    
    // í˜¼í•© íŒ¨í„´ ê°ì§€ (í•œêµ­ì–´+ì˜ì–´+ìˆ«ì)
    const mixedPattern = segment.match(/([ê°€-í£]+)|([a-zA-Z]+[0-9]*)|([0-9]+[a-zA-Z]*)/g);
    if (mixedPattern && mixedPattern.length > 1) {
      console.log(`Mixed pattern detected: [${mixedPattern.join(', ')}]`);
      return mixedPattern.filter(part => part.length >= 1);
    }
    
    // ìˆœìˆ˜ í•œêµ­ì–´ ì„¸ê·¸ë¨¼íŠ¸ ë¶„ì„
    if (/^[ê°€-í£]+$/.test(segment)) {
      if (segment.length >= 4) {
        // 4ê¸€ì ì´ìƒì¸ ê²½ìš° 2+2 ë˜ëŠ” 3+ë‚˜ë¨¸ì§€ë¡œ ë¶„í•  ì‹œë„
        const firstHalf = segment.substring(0, 2);
        const secondHalf = segment.substring(2);
        
        // ë’·ë¶€ë¶„ì´ ì¼ë°˜ì ì¸ ì ‘ë¯¸ì‚¬ íŒ¨í„´ì¸ì§€ í™•ì¸
        if (suffixPatterns.some(suffix => secondHalf.startsWith(suffix))) {
          return [firstHalf, secondHalf];
        }
        
        // 3+ë‚˜ë¨¸ì§€ íŒ¨í„´ ì‹œë„
        if (segment.length >= 5) {
          const first3 = segment.substring(0, 3);
          const rest = segment.substring(3);
          return [first3, rest];
        }
        
        // ê¸°ë³¸ 2+2 ë¶„í• 
        return [firstHalf, secondHalf];
      } else if (segment.length >= 2) {
        return [segment];
      }
    }
    
    // ìˆœìˆ˜ ì˜ì–´+ìˆ«ì ì„¸ê·¸ë¨¼íŠ¸
    if (/^[a-zA-Z0-9]+$/.test(segment)) {
      // ì˜ì–´+ìˆ«ì ì¡°í•©ì€ ê·¸ëŒ€ë¡œ ìœ ì§€ (ì˜ˆ: "a6", "520d")
      return [segment];
    }
    
    return [];
  }
  
  const decomposed = smartDecompose(text);
  console.log(`Decomposed "${text}" â†’ [${decomposed.join(', ')}]`);
  
  return decomposed;
}

// ğŸ†• ë”ë¸” ì²´í¬: íŒ¨í„´ ê¸°ë°˜ + AI ê¸°ë°˜ ë¹„êµ
async function doubleCheckDecomposition(keyword: string): Promise<string[]> {
  console.log(`ğŸ” Double-check decomposition for: "${keyword}"`);
  
  // ë°©ë²• 1: ë¹ ë¥¸ íŒ¨í„´ ê¸°ë°˜
  const patternBased = fallbackPatternDecomposer(keyword);
  console.log(`  íŒ¨í„´ ê¸°ë°˜: [${patternBased.join(', ')}]`);
  
  // ë°©ë²• 2: ì •í™•í•œ AI ê¸°ë°˜
  const aiBased = await aiBasedKeywordDecomposer(keyword);
  console.log(`  AI ê¸°ë°˜: [${aiBased.join(', ')}]`);
  
  // ê²°ê³¼ ë¹„êµ ë° ìµœì¢… ê²°ì •
  if (patternBased.length === aiBased.length && 
      patternBased.every((word, i) => word === aiBased[i])) {
    console.log(`  âœ… ì¼ì¹˜! ê²°ê³¼ ì‚¬ìš©: [${aiBased.join(', ')}]`);
    return aiBased;
  }
  
  // ë¶ˆì¼ì¹˜ ì‹œ AI ìš°ì„  (ë” ì •í™•í•¨)
  console.log(`  âš ï¸ ë¶ˆì¼ì¹˜ ê°ì§€. AI ê²°ê³¼ ìš°ì„  ì‚¬ìš©: [${aiBased.join(', ')}]`);
  console.log(`  ì°¸ê³ ìš© íŒ¨í„´ ê²°ê³¼: [${patternBased.join(', ')}]`);
  return aiBased;
}

// Extract individual keyword components for SEO optimization (ğŸ†• ë”ë¸” ì²´í¬ ê¸°ë°˜)
export async function extractKeywordComponents(keyword: string): Promise<string[]> {
  const components: string[] = [];
  
  console.log(`=== Starting double-check keyword decomposition for: "${keyword}" ===`);
  
  // Handle compound keywords with comma separator
  if (keyword.includes(',')) {
    console.log('Comma-separated compound keyword detected');
    const parts = keyword.split(',').map(part => part.trim()).filter(Boolean);
    console.log('Split parts:', parts);
    
    // For compound keywords, treat each complete part as the main component
    for (const part of parts) {
      if (part.length > 0) {
        components.push(part);
        
        // ğŸ†• ë”ë¸” ì²´í¬ ë¶„í•´
        const subComponents = await doubleCheckDecomposition(part);
        for (const subComp of subComponents) {
          if (subComp.length >= 2 && !components.includes(subComp)) {
            components.push(subComp);
          }
        }
      }
    }
  } else {
    // ğŸ†• Single keyword double-check decomposition
    const decomposed = await doubleCheckDecomposition(keyword);
    console.log(`Double-check decomposition result: [${decomposed.join(', ')}]`);
    
    for (const comp of decomposed) {
      if (!components.includes(comp) && comp.length >= 1) {
        components.push(comp);
      }
    }
  }
  
  console.log(`Keyword components extracted from "${keyword}":`, components);
  return components;
}

// Find complete keyword matches - ì™„ì „í•œ í‚¤ì›Œë“œì˜ ì •í™•í•œ ì¶œí˜„ë§Œ ì¹´ìš´íŠ¸
export function findCompleteKeywordMatches(morphemes: string[], keyword: string): string[] {
  const matches: string[] = [];
  console.log(`Looking for complete keyword: "${keyword}"`);
  
  // Handle compound keywords with comma separator
  if (keyword.includes(',')) {
    const parts = keyword.split(',').map(part => part.trim()).filter(Boolean);
    console.log('Looking for compound keyword parts:', parts);
    
    // For compound keywords, we need to be more selective about what counts as "complete"
    // Count only instances where BOTH parts appear close together or as the full compound
    let compoundMatches = 0;
    
    // Look for cases where both parts appear near each other in the text
    const fullText = morphemes.join(' ').toLowerCase();
    const part1 = parts[0].toLowerCase();
    const part2 = parts[1]?.toLowerCase();
    
    if (part1 && part2) {
      // Count occurrences where both parts appear within reasonable proximity (within 50 characters)
      let searchIndex = 0;
      while (searchIndex < fullText.length) {
        const index1 = fullText.indexOf(part1, searchIndex);
        if (index1 === -1) break;
        
        const index2 = fullText.indexOf(part2, index1);
        if (index2 !== -1 && (index2 - index1) <= 50) {
          compoundMatches++;
          console.log(`âœ“ Compound keyword proximity match found: "${part1}" + "${part2}"`);
          searchIndex = index1 + part1.length;
        } else {
          searchIndex = index1 + part1.length;
        }
      }
      
      // Add dummy matches to reach the compound count
      for (let i = 0; i < compoundMatches; i++) {
        matches.push(`${parts[0]}, ${parts[1]}`);
      }
    }
    
    // Also look for the complete compound keyword written together (less common)
    const fullKeyword = keyword.replace(/,\s*/g, ''); // Remove comma and spaces
    const lowerFullKeyword = fullKeyword.toLowerCase();
    for (const morpheme of morphemes) {
      const lowerMorpheme = morpheme.toLowerCase();
      if (lowerMorpheme === lowerFullKeyword || 
          (lowerMorpheme.startsWith(lowerFullKeyword) && 
           lowerMorpheme.length <= lowerFullKeyword.length + 2)) {
        matches.push(morpheme);
        console.log(`âœ“ Complete compound keyword match: "${morpheme}"`);
      }
    }
  } else {
    // Single keyword matching
    const lowerKeyword = keyword.toLowerCase();
    for (const morpheme of morphemes) {
      const lowerMorpheme = morpheme.toLowerCase();
      
      // ì™„ì „í•œ í‚¤ì›Œë“œ ìì²´ ë˜ëŠ” ì¡°ì‚¬ê°€ ë¶™ì€ í˜•íƒœë§Œ ì¸ì •
      if (lowerMorpheme === lowerKeyword || 
          (lowerMorpheme.startsWith(lowerKeyword) && 
           lowerMorpheme.length <= lowerKeyword.length + 2)) {
        matches.push(morpheme);
        console.log(`âœ“ Complete keyword match: "${morpheme}"`);
      }
    }
  }
  
  console.log(`Total complete keyword matches found: ${matches.length}`);
  return matches;
}

/**
 * Detect if a component is a foreign word (English, numbers, mixed)
 */
function isForeignWord(component: string): boolean {
  // Contains Latin alphabet or numbers
  return /[a-zA-Z0-9]/.test(component);
}

/**
 * Intelligent matching for keyword components
 * Handles both Korean and foreign words appropriately
 */
function isComponentMatch(morpheme: string, component: string): boolean {
  const lowerMorpheme = morpheme.toLowerCase();
  const lowerComponent = component.toLowerCase();
  
  // Exact match (case-insensitive)
  if (lowerMorpheme === lowerComponent) {
    return true;
  }
  
  // Detect if component is foreign word
  const isForeign = isForeignWord(component);
  
  if (isForeign) {
    // For foreign words (English, numbers, mixed):
    // Match if morpheme contains the component as a whole word or part
    // Examples: "BMW" matches "bmw", "BMW", "Bmw"
    //           "10w40" matches "10w40", "10W40"
    
    // Exact case-insensitive match
    if (lowerMorpheme === lowerComponent) {
      return true;
    }
    
    // Contains match for foreign words in compound contexts
    // Example: "ì—”ì§„ì˜¤ì¼10w40" should match "10w40"
    if (lowerMorpheme.includes(lowerComponent)) {
      return true;
    }
    
    // Also check if morpheme starts or ends with the component
    // This helps with cases like "BMWì½”ë”©" matching "BMW"
    if (lowerMorpheme.startsWith(lowerComponent) || lowerMorpheme.endsWith(lowerComponent)) {
      return true;
    }
  } else {
    // For Korean words:
    // More flexible matching to catch compound words
    // Examples: "ë²¤ì¸ " should match "ë²¤ì¸ ì—”ì§„ê²½ê³ ë“±"
    //           "ì—”ì§„" should match "ë²¤ì¸ ì—”ì§„", "ì—”ì§„ì˜¤ì¼"
    
    // Exact match
    if (lowerMorpheme === lowerComponent) {
      return true;
    }
    
    // Contains match for Korean components (allows finding in compound words)
    if (lowerMorpheme.includes(lowerComponent)) {
      return true;
    }
    
    // Check if component appears as a distinct part
    // This handles cases where the component is a meaningful unit within a larger word
    const componentLength = component.length;
    if (componentLength >= 2 && lowerMorpheme.includes(lowerComponent)) {
      return true;
    }
  }
  
  return false;
}

// Find individual keyword component matches (for 15-17 occurrences each)
export async function findKeywordComponentMatches(morphemes: string[], keyword: string): Promise<Map<string, string[]>> {
  const keywordComponents = await extractKeywordComponents(keyword);
  const componentMatches = new Map<string, string[]>();
  
  console.log(`Target keyword components:`, keywordComponents);
  console.log(`Sample content morphemes:`, morphemes.slice(0, 30));
  
  for (const component of keywordComponents) {
    const matches: string[] = [];
    const componentType = isForeignWord(component) ? 'ì™¸ë˜ì–´' : 'í•œê¸€';
    
    console.log(`\nğŸ” Analyzing component: "${component}" (${componentType})`);
    
    for (const morpheme of morphemes) {
      if (isComponentMatch(morpheme, component)) {
        matches.push(morpheme);
        console.log(`  âœ“ Match found: "${morpheme}"`);
      }
    }
    
    componentMatches.set(component, matches);
    console.log(`ğŸ“Š "${component}" appears ${matches.length} times in content`);
  }
  
  return componentMatches;
}

// Check if custom morphemes are present in content
function checkCustomMorphemes(content: string, customMorphemes?: string): { used: string[], missing: string[] } {
  if (!customMorphemes) {
    return { used: [], missing: [] };
  }
  
  const morphemesArray = customMorphemes.split(' ').filter(m => m.trim().length > 0);
  const contentLower = content.toLowerCase();
  const used: string[] = [];
  const missing: string[] = [];
  
  console.log(`Checking custom morphemes:`, morphemesArray);
  
  for (const morpheme of morphemesArray) {
    if (contentLower.includes(morpheme.toLowerCase())) {
      used.push(morpheme);
      console.log(`âœ“ Custom morpheme found: "${morpheme}"`);
    } else {
      missing.push(morpheme);
      console.log(`âœ— Custom morpheme missing: "${morpheme}"`);
    }
  }
  
  return { used, missing };
}

// ì „ì²´ í˜•íƒœì†Œ ë¹ˆë„ ê²€ì‚¬ í•¨ìˆ˜ (20íšŒ ì´ˆê³¼ ë°©ì§€)
async function checkAllMorphemeFrequencies(content: string, keyword: string): Promise<{ overused: Array<{morpheme: string, count: number}>, allCounts: Map<string, number> }> {
  console.log('ğŸ” ì „ì²´ í˜•íƒœì†Œ ë¹ˆë„ ê²€ì‚¬ ì‹œì‘...');
  
  const allMorphemes = extractKoreanMorphemes(content);
  const keywordComponents = await extractKeywordComponents(keyword);
  const keywordComponentsLower = keywordComponents.map(comp => comp.toLowerCase());
  
  // ëª¨ë“  í˜•íƒœì†Œ ë¹ˆë„ ê³„ì‚°
  const morphemeFrequency = new Map<string, number>();
  allMorphemes.forEach(morpheme => {
    const cleanMorpheme = morpheme.toLowerCase();
    morphemeFrequency.set(cleanMorpheme, (morphemeFrequency.get(cleanMorpheme) || 0) + 1);
  });
  
  // ê³¼ë‹¤ ì‚¬ìš© í˜•íƒœì†Œ ì°¾ê¸° (í‚¤ì›Œë“œ ìš°ìœ„ì„± í™•ë³´)
  const overused: Array<{morpheme: string, count: number}> = [];
  for (const [morpheme, count] of Array.from(morphemeFrequency.entries())) {
    const isKeywordComponent = keywordComponentsLower.includes(morpheme);
    const maxAllowed = isKeywordComponent ? 18 : 14; // í‚¤ì›Œë“œ: 15-18íšŒ, ë‹¤ë¥¸ ë‹¨ì–´: 14íšŒ ì´í•˜
    
    if (count > maxAllowed) {
      overused.push({ morpheme, count });
      console.log(`âŒ "${morpheme}" ì´ˆê³¼ ì‚¬ìš©: ${count}íšŒ (ìµœëŒ€ ${maxAllowed}íšŒ) ${isKeywordComponent ? '[í‚¤ì›Œë“œ í˜•íƒœì†Œ]' : '[ì¼ë°˜ í˜•íƒœì†Œ]'}`);
    }
  }
  
  console.log(`ì „ì²´ í˜•íƒœì†Œ ë¹ˆë„ ê²€ì‚¬ ì™„ë£Œ. ì´ˆê³¼ ì‚¬ìš©: ${overused.length}ê°œ`);
  return { overused, allCounts: morphemeFrequency };
}

export async function analyzeMorphemes(content: string, keyword: string, customMorphemes?: string): Promise<MorphemeAnalysis> {
  console.log(`=== Morpheme Analysis for keyword: "${keyword}" ===`);
  
  try {
    // ì „ì²´ í˜•íƒœì†Œ ë¹ˆë„ ë¨¼ì € ê²€ì‚¬
    const frequencyCheck = await checkAllMorphemeFrequencies(content, keyword);
    
    // Extract all morphemes from content
    const allMorphemes = extractKoreanMorphemes(content);
    console.log(`Total morphemes extracted: ${allMorphemes.length}`);
    
    // Calculate character count (excluding spaces)
    const characterCount = content.replace(/\s/g, '').length;
  
  // Find complete keyword matches (minimum 5 required)
  const completeKeywordMatches = findCompleteKeywordMatches(allMorphemes, keyword);
  const completeKeywordCount = completeKeywordMatches.length;
  
  // Find individual component matches (15-18íšŒ í—ˆìš©)
  const componentMatches = await findKeywordComponentMatches(allMorphemes, keyword);
  const keywordComponents = await extractKeywordComponents(keyword);
  
  // Check complete keyword condition (5-7 times)
  const isCompleteKeywordOptimized = completeKeywordCount >= 5 && completeKeywordCount <= 7;
  
  // Check individual component conditions (15-18 times each) - ì‹¤ìš©ì ì¸ SEO ê¸°ì¤€
  let areComponentsOptimized = true;
  const componentIssues: string[] = [];
  
  console.log(`Complete keyword "${keyword}" appears: ${completeKeywordCount} times (5-7 times required)`);
  
  for (const component of keywordComponents) {
    const matches = componentMatches.get(component) || [];
    const count = matches.length;
    
    if (count < 15 || count > 18) {
      areComponentsOptimized = false;
      if (count < 15) {
        componentIssues.push(`${component}: ${count}íšŒ (ë¶€ì¡±, 15-18íšŒ ê¶Œì¥)`);
      } else if (count > 18) {
        componentIssues.push(`${component}: ${count}íšŒ (ê³¼ë‹¤, 15-18íšŒ ê¶Œì¥)`);
      }
    }
  }
  
  // Check length condition (1700-2000 characters excluding spaces)
  const isLengthOptimized = characterCount >= 1700 && characterCount <= 2000;
  
  // Overall keyword optimization status
  const isKeywordOptimized = isCompleteKeywordOptimized && areComponentsOptimized;
  
  // Check custom morphemes
  const customMorphemeCheck = checkCustomMorphemes(content, customMorphemes);
  const isCustomMorphemesOptimized = customMorphemeCheck.missing.length === 0;
  
  // í˜•íƒœì†Œ ë¹ˆë„ ê²€ì‚¬ ê²°ê³¼ ë°˜ì˜
  const hasOverusedMorphemes = frequencyCheck.overused.length > 0;
  const isOptimized = isLengthOptimized && isKeywordOptimized && !hasOverusedMorphemes;
  
  // Generate issues and suggestions
  const issues: string[] = [];
  const suggestions: string[] = [];
  
  // Add specific issues and suggestions
  if (!isCompleteKeywordOptimized) {
    if (completeKeywordCount < 5) {
      issues.push(`ì™„ì „í•œ í‚¤ì›Œë“œ "${keyword}" ì¶œí˜„ íšŸìˆ˜ ë¶€ì¡±: ${completeKeywordCount}íšŒ (5-7íšŒ í•„ìš”)`);
      suggestions.push(`í‚¤ì›Œë“œ "${keyword}"ë¥¼ 5-7íšŒ ì‚¬ìš©í•´ì£¼ì„¸ìš”`);
    } else if (completeKeywordCount > 7) {
      issues.push(`ì™„ì „í•œ í‚¤ì›Œë“œ "${keyword}" ì¶œí˜„ íšŸìˆ˜ ê³¼ë‹¤: ${completeKeywordCount}íšŒ (5-7íšŒ í•„ìš”)`);
      suggestions.push(`í‚¤ì›Œë“œ "${keyword}"ë¥¼ 7íšŒ ì´í•˜ë¡œ ì¤„ì—¬ì£¼ì„¸ìš”`);
    }
  }
  
  if (!areComponentsOptimized) {
    for (const issue of componentIssues) {
      issues.push(`í˜•íƒœì†Œ ì¶œí˜„ íšŸìˆ˜ ë¶ˆê· í˜•: ${issue}`);
    }
    suggestions.push(`í‚¤ì›Œë“œ êµ¬ì„± ìš”ì†Œë“¤(${keywordComponents.join(', ')})ì„ ê°ê° 16íšŒë¥¼ ëª©í‘œë¡œ ì‚¬ìš©í•´ì£¼ì„¸ìš” (15-18íšŒ í—ˆìš©)`);
  }
  
  if (!isLengthOptimized) {
    if (characterCount < 1700) {
      issues.push(`ê¸€ììˆ˜ ë¶€ì¡±: ${characterCount}ì (1700-2000ì í•„ìš”)`);
      suggestions.push(`ë‚´ìš©ì„ ì¶”ê°€í•˜ì—¬ 1700ì ì´ìƒìœ¼ë¡œ ëŠ˜ë ¤ì£¼ì„¸ìš”`);
    } else if (characterCount > 2000) {
      issues.push(`ê¸€ììˆ˜ ì´ˆê³¼: ${characterCount}ì (1700-2000ì í•„ìš”)`);
      suggestions.push(`ë‚´ìš©ì„ ì¤„ì—¬ì„œ 2000ì ì´í•˜ë¡œ ë§ì¶°ì£¼ì„¸ìš”`);
    }
  }
  
  if (!isCustomMorphemesOptimized && customMorphemes) {
    issues.push(`ëˆ„ë½ëœ í•„ìˆ˜ í˜•íƒœì†Œ: ${customMorphemeCheck.missing.join(', ')}`);
    suggestions.push(`ë‹¤ìŒ ë‹¨ì–´ë“¤ì„ ê¸€ì— í¬í•¨í•´ì£¼ì„¸ìš”: ${customMorphemeCheck.missing.join(', ')}`);
  }
  
  // í˜•íƒœì†Œ ì´ˆê³¼ ì‚¬ìš© ê²€ì‚¬ ê²°ê³¼ ì¶”ê°€
  if (hasOverusedMorphemes) {
    const keywordComponentsLower = keywordComponents.map(comp => comp.toLowerCase());
    for (const overused of frequencyCheck.overused) {
      const isKeywordComponent = keywordComponentsLower.includes(overused.morpheme.toLowerCase());
      const maxAllowed = isKeywordComponent ? 18 : 14;
      issues.push(`í˜•íƒœì†Œ ê³¼ë‹¤ ì‚¬ìš©: "${overused.morpheme}" ${overused.count}íšŒ (ìµœëŒ€ ${maxAllowed}íšŒ)`);
    }
    suggestions.push(`ê³¼ë‹¤ ì‚¬ìš©ëœ í˜•íƒœì†Œë“¤ì„ ë™ì˜ì–´ë‚˜ ìœ ì˜ì–´ë¡œ êµì²´í•´ì£¼ì„¸ìš”`);
  }

  return {
    isOptimized,
    isKeywordOptimized,
    isLengthOptimized,
    keywordMorphemeCount: completeKeywordCount,
    characterCount,
    targetCharacterRange: '1700-2000ì',
    issues,
    suggestions,
    customMorphemes: customMorphemeCheck,
    isCustomMorphemesOptimized
  };
  
  } catch (error) {
    console.error(`Morpheme analysis failed for keyword "${keyword}":`, error);
    return {
      isOptimized: false,
      isKeywordOptimized: false,
      isLengthOptimized: false,
      keywordMorphemeCount: 0,
      characterCount: content.replace(/\s/g, '').length,
      targetCharacterRange: '1700-2000ì',
      issues: ['í˜•íƒœì†Œ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤'],
      suggestions: ['í‚¤ì›Œë“œë¥¼ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”'],
      customMorphemes: { used: [], missing: [] },
      isCustomMorphemesOptimized: false
    };
  }
}

// Enhanced SEO analysis combining morpheme analysis with basic metrics
export async function enhancedSEOAnalysis(content: string, keyword: string) {
  const morphemeAnalysis = await analyzeMorphemes(content, keyword);
  
  return {
    keywordFrequency: morphemeAnalysis.keywordMorphemeCount,
    characterCount: morphemeAnalysis.characterCount,
    morphemeCount: morphemeAnalysis.keywordMorphemeCount,
    isOptimized: morphemeAnalysis.isOptimized,
    issues: morphemeAnalysis.issues,
    suggestions: morphemeAnalysis.suggestions,
    targetCharacterRange: morphemeAnalysis.targetCharacterRange
  };
}